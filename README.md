ğŸ§  FastAPI + OpenAI Chat Assistant

This project is a chat assistant built with FastAPI (backend), React (frontend), and OpenAIâ€™s API.
Users can ask questions via a React client, which are sent to the FastAPI backend.
The backend forwards the question to OpenAIâ€™s GPT model and returns the generated response.

âš ï¸ Note:
This middleware was added just to demonstrate how to create a middleware in FastAPI.
In real-world deployments, client IP checks are usually handled by a reverse proxy server (e.g., Nginx, Traefik, HAProxy).
That way, invalid requests never even reach your FastAPI app â€” saving server resources and bandwidth.

ğŸš€ Features

âœ… FastAPI backend with clean API routes

âœ… OpenAI GPT integration using the official SDK

âœ… Frontend client (React) for interactive Q&A

âœ… Typed responses with Pydantic schemas

âœ… Environment variable support via .env

.
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ routers/
â”‚ â”‚ â””â”€â”€ ask_ai.py # FastAPI route for AI Q&A
â”‚ â”œâ”€â”€ app_logic.py # Logic for calling OpenAI
â”‚ â”œâ”€â”€ schemas.py # Pydantic models for validation
â”‚ â””â”€â”€ **init**.py
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ src/ChatBox.jsx # React chat component
â”œâ”€â”€ .env # Environment variables (not committed)
â”œâ”€â”€ requirements.txt # Backend dependencies
â”œâ”€â”€ package.json # Frontend dependencies
â””â”€â”€ README.md # Documentation

âš™ï¸ Installation
1ï¸âƒ£ Clone the repo
git clone https://github.com/your-username/fastapi-openai-chat.git
cd fastapi-openai-chat

2ï¸âƒ£ Backend Setup (FastAPI)

Create a virtual environment and install dependencies:

python -m venv venv
source venv/bin/activate # Linux / Mac
venv\Scripts\activate # Windows

pip install -r requirements.txt

Set up your .env file:

OPENAI_API_KEY=your_openai_api_key_here

Run the FastAPI backend:

uvicorn app.main:app --reload

API will be available at:
ğŸ‘‰ http://localhost:8000/docs

3ï¸âƒ£ Frontend Setup (React)

Go to the frontend folder:

cd frontend
npm install
npm run dev # or npm start

React app will be running on:
ğŸ‘‰ http://localhost:5173 (if using Vite)
ğŸ‘‰ http://localhost:3000 (if using CRA)

ğŸ“¡ API Endpoints
POST /ask-ai

Ask a question to the AI.

Query Parameters:

question (string, max 100 chars) â†’ The question to send to the AI.
